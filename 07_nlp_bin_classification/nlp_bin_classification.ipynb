{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разработка модели для классифицикации комментариев на позитивные и негативные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Цель работы:**<br>\n",
    "Построить модель, которая определит тональность комментариев в новом сервисе закачика.\n",
    "\n",
    "**Планируемое использование результата работы:**<br>\n",
    "Заказчику необходим инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "**Входные данные:**<br>\n",
    "Заказчик предоставил набор данных с разметкой о токсичности. Негативный комментарий - класс 1, нейтральный комментарий - класс 0.\n",
    "\n",
    "**Задачи работы:**\n",
    "1. Подготовить данные для формирования модели.\n",
    "2. Разработать несколько моделей машинного обучения (МО) для предсказания.\n",
    "3. Оценить качество работы моделей. Выбрать лучшую модель.\n",
    "4. Протестировать лучшую модель.\n",
    "\n",
    "**Дополнительные критерии заказчика:**\n",
    "\n",
    "- Значение метрики F1 на тестовой выборке должно быть не мешьше 0.75.\n",
    "\n",
    "**План работы:**\n",
    "<a id='begin'></a>\n",
    "\n",
    "1. Шаг 1. Подготовка данных.\n",
    "    - [[Перейти к разделу]](#step11). [[Перейти к выводу]](#conclusion11). Загрузка и зучение данных. Изучить входные данные, оценить полноту и качество входных данных для достижения цели исследования. Определить задачи предобработки данных.\n",
    "    - [[Перейти к разделу]](#step12). [[Перейти к выводу]](#conclusion12). Преобработка данных. Осуществить предобработку данных в части улучшения качества данных для дальнейшего анализа.\n",
    "    - [[Перейти к разделу]](#step13). [[Перейти к выводу]](#conclusion13). Исследовательский анализ данных. Провести исследовательский анализ данных, оценить (уточнить) необходимость формирования дополнительных категорий, параметров и групп данных для достижения цели исследования, провести корреляционный анализ данных.\n",
    "    - [[Перейти к разделу]](#step14). [[Перейти к выводу]](#conclusion14). Подготовка данных к обучению, в том числе объединение или разделение необходимых данных в единый или различные дата-сеты, формирование новых признаков, дополнительных категорий и групп данных.\n",
    "2. Шаг 2. Разработка моделей МО.\n",
    "    - [[Перейти к разделу]](#step21). [[Перейти к выводу]](#conclusion21). Определение условий разработки моделей МО. Определиться с критериями разработки моделей, метриками качества моделей, критериями сравнения моделей.\n",
    "    - [[Перейти к разделу]](#step22). [[Перейти к выводу]](#conclusion22). Основной этап моделирования. Разработать модели машинного обучения. Получить результаты для анализа их качества и скорости.\n",
    "3. Шаг 3. [[Перейти к разделу]](#step3). Оценка качества работы моделей, выбор лучшей модели, оценка качества модели на тестовой выборке.\n",
    "\n",
    "**[[Итоговый вывод]](#conclusion)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spacy.__version__ != '3.2.6':\n",
    "    print('Pls, restart the kernel')\n",
    "    print(spacy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объявление констант и установок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_time_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 546859"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_VALID_SIZE = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_PROCESS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка и изучение данных \n",
    "\n",
    "<a id='step11' />\n",
    "\n",
    "[Вернуться к началу](#begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv(\n",
    "        '../../datasets/toxic_comments.csv',\n",
    "        index_col=0\n",
    "    )\n",
    "except (Exception) as e: \n",
    "    print(e)\n",
    "    data = pd.read_csv(\n",
    "        'https://code.s3.yandex.net/datasets/toxic_comments.csv',\n",
    "        index_col=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучим общие сведения о данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод по разделу \"Загрузка и изучение входных данных\" \n",
    "\n",
    "<a id='conclusion11' />\n",
    "\n",
    "[Вернуться к началу](#begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основании общих сведений о входных данных таблицы `data` сделаны следующие выводы:\n",
    "\n",
    "1. Данные содержат два столбца, один из которых cодержит комментарии для анализа, второй - целевой признак токсичности комментария.\n",
    "2. На первый взгляд данные представлены на английском языке. Проверим это. \n",
    "3. Пропусков в данных не выявлено, целесообразно проверить данные на дубликаты без учета целевого признака."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобработка данных \n",
    "\n",
    "<a id='step12' />\n",
    "\n",
    "[Вернуться к началу](#begin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прозведем предобработку данных на основании ранее сделанных выводов:\n",
    "\n",
    "1. Пропусков в данных не имеется.\n",
    "2. Проверим наличие кириллических символов.\n",
    "3. Проверим наличие дубликатов в столбце `text` и обработаем их при необходимости.\n",
    "4. Обработаем типы данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предварительно создадим копию входных данных для текущего этапа работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_data = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим наличие дубликатов в столбце `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_data.duplicated(subset='text').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дубликатов не имеется."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию, которая оставит в тексте только латинские символы, пробелы и знак апострофа. На вход она принимает текст, а возвращает очищенный текст. Дополнительно уберем лишние пробелы. Также приведем все слова к нижнему регистру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    cleared_text = re.sub(r'[^a-zA-Z\\'\\❜]', ' ', text)\n",
    "    cleared_text = re.sub(r'((\\w)\\2{2,})', ' ', cleared_text).split()   \n",
    "    cleared_text = ' '.join(cleared_text).lower()\n",
    "    return cleared_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_data['cleared_text'] = preprocessing_data['text'].progress_apply(clear_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию, которая на вход принимает текст и возвращает лемматизированную строку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    token = nltk.word_tokenize(text)\n",
    "    text = [word for word in token]\n",
    "    text = [lemmatizer.lemmatize(word,pos='v') for word in text]\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_data['lemmatized_text'] = preprocessing_data['cleared_text'].progress_apply(lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем также лемматизацию с использованием библиотеки spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_spaCy(df, original='text'):\n",
    "    if not BIG_PROCESS:\n",
    "        try:\n",
    "            spacy_lemmas = pd.read_csv('lemmatized_spaCy.csv', index_col=0)\n",
    "            return spacy_lemmas['lemmatized_spaCy'].str.lower()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    df = df.copy()\n",
    "    nlp = en_core_web_sm.load()\n",
    "    \n",
    "    def lemmatize(text):\n",
    "        lemmatized_text = nlp(text)\n",
    "        lemmatized_text = (\n",
    "            \" \".join([token.lemma_ for token in lemmatized_text])\n",
    "        )\n",
    "        return lemmatized_text\n",
    "    \n",
    "    lemmatized = df[original].progress_apply(lemmatize)\n",
    "    \n",
    "    df['lemmatized_spaCy'] = lemmatized\n",
    "    \n",
    "    df['lemmatized_spaCy'].to_csv('lemmatized_spaCy.csv')\n",
    "    \n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако, лематизация с использованием этого инструмента занимает слишком много времени. В связи с этим, загрузим готовый результат из файла, созданного локально"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_data['lemmatized_text_spacy'] = lemmatize_spaCy(preprocessing_data, 'cleared_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучим результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_result = preprocessing_data.loc[[74584]]\n",
    "#show_result = preprocessing_data.sample(1)\n",
    "print(\"---> Идентификатор текста:\\n\", show_result.index)\n",
    "print()\n",
    "print(\"---> Пример исходного текста:\\n\", show_result.iloc[0,0])\n",
    "print()\n",
    "print(\"---> Пример очищенного текста:\\n\", show_result.iloc[0,2])\n",
    "print()\n",
    "print(\"---> Пример лемматизированного текста:\\n\", show_result.iloc[0,3])\n",
    "print()\n",
    "print(\"---> Пример лемматизированного текста через Spacy:\\n\", show_result.iloc[0,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рассмотренном примере мы наблюдаем следующее:\n",
    "1. Удалены не латинские символы. Даже в имени автора - José Luis Gómez Pérez. В таких ситуациях мы вместо слов получаем отдельные буквы. Целесообразно продумать вариант обработки таких случаев. В настоящей работе этого делать не будем.\n",
    "2. При лемматизации с использованием nltk сокрашения типа I'm определяются верно, однако сокращения с not не могут быть лемматизированы.\n",
    "3. При лемматизации с использованием spaCy этой проблемы не имеется."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим на наличие пропусков после лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_data[preprocessing_data['lemmatized_text_spacy'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все верно. Некоторые сообщения не содержать буквенных симоволов. Следовательно после очистки тексы были представлены как пустые. Удалим такие строки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_data = preprocessing_data[~preprocessing_data['lemmatized_text_spacy'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод по разделу \"Преобработка данных\" \n",
    "\n",
    "<a id='conclusion12' />\n",
    "\n",
    "[Вернуться к началу](#begin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе предобработки данных были достигнуты следующие результаты:\n",
    "\n",
    "1. Пропусков и дубликатов в данных не обнаружено.\n",
    "2. Произведена преобработка текстовых данных: токенизация, очистка и лемматизация. Лучший результат лемматизации показала библиотека spaCy.\n",
    "\n",
    "Предобработка данных завершена, данные готовы к дальнейшему анализу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исследовательский анализ данных \n",
    "\n",
    "<a id='step13' />\n",
    "\n",
    "[Вернуться к началу](#begin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках исследовательского анализа данных оценим баланс классов нашей задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_data = preprocessing_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_data['toxic'].value_counts().plot(\n",
    "    kind='pie', \n",
    "    autopct = '%1.0f%%',\n",
    "    ylabel = '',\n",
    "    title = 'Соотношение целевого признака. Столбец [toxic]',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Вывод по разделу \"Исследовательский анализ данных\" \n",
    "\n",
    "<a id='conclusion13' />\n",
    "\n",
    "[Вернуться к началу](#begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате проведения исследовательского анализа было выявлено, что имеется существенный дисбаланс классов. Устранять его не будем, но учтем при делении на выборки (stratify) и при обучении модели (аттрибут class_weight='balanced')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных \n",
    "\n",
    "<a id='step14' />\n",
    "\n",
    "[Вернуться к началу](#begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате проведенной работы определено, что в работе необходимо решить задачу бинарной классификации для текстов с применением техник NLP. Для формирования модели необходимо сгенерировать признаки путем векторизации предобработанных текстов. Перед векторизацией необходимо разбить данные на выборки: обучающую, валидационную и тестовую; в связи с тем, что первичную векторизацию необходимо реализовавыть на обучающей выборке и затем алгоритмы векторизации использовать на валидационной и тестовой выборках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предварительно создадим копию входных данных для текущего этапа работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data = eda_data.copy()\n",
    "process_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на обучающую и тестовую выборки в отношении 0.6:0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = process_data\n",
    "y = process_data['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_VALID_SIZE, random_state=RANDOM_STATE, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим функцию обучения, кросс-валидации и тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model, vectorizer, \n",
    "              X_train, column, y_train,\n",
    "              X_test=None, y_test=None):\n",
    "    model = make_pipeline(vectorizer, model)\n",
    "    if X_test is None or y_test is None:\n",
    "        score = cross_val_score(model, X_train[column], y_train,\n",
    "                               scoring='f1', cv=3, n_jobs=6).mean()\n",
    "    else:\n",
    "        model.fit(X_train[column], y_train)\n",
    "        y_pred = model.predict(X_test[column])\n",
    "        score = f1_score(y_test, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод по разделу \"Подготовка данных\" \n",
    "\n",
    "<a id='conclusion14' />\n",
    "\n",
    "[Вернуться к началу](#begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пайплайн подготовлен с учетом принципов работы с текстами:\n",
    "1. На вход подается векторайзер для формирования векторов текста.\n",
    "2. На вход подается только один столбец с текстами.\n",
    "3. Применена кросс-валидация, по которой будем оценивать качество модели.\n",
    "4. При передаче в функцию тестовых данных, она вернет результирующую оценку для тестовой выборки.\n",
    "\n",
    "В ходе работы также подготовлены тренировочная и тестовая выборки. Данные тестовой выборки будут использованы только в конце работы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 2. Разработка моделей МО\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определение условий разработки моделей МО \n",
    "\n",
    "<a id='step21' />\n",
    "\n",
    "[Вернуться к началу](#begin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Постановка задачи**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заказчиком поставлена задача бинарной классификации с применением техник NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выбор метрики**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задачах бинарной классификации используются различные метрики. В связи с тем, что в решаемой задаче нет необходимости минимизировать ошибку I или II рода, целесообразно использовать обобщенную метрику. Таковой является F1-мера."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Необходимый уровень метрики**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Заказчик установил в качестве критерия качества моделей указанную метрику в уровне не менее 0,75 на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**План основного этапа моделирования**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основании сделанных выводов и поставленных задач на основном этапе моделирования выполним следующие шаги:\n",
    "1. Доработаем входные данные, исключив стоп-слова, не несущие смысловой нагрузки.\n",
    "2. Используем два векторайзера для получения векторов текстов: CountVectorizer() и TfidfVectorizer().\n",
    "3. Построим три модели для сравнения: LogisticRegression(), LinearSVC(), LightGBM.\n",
    "4. Получим результаты кросс-валидации трех моделей для каждого векторайзера.\n",
    "5. Кроме того, произведем построение моделей для двух видом лемматизации текстов: с использованием WordNet и spaCy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Вывод по разделу \"Определение условий разработки моделей МО\" \n",
    "\n",
    "<a id='conclusion21' />\n",
    "\n",
    "[Вернуться к началу](#begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате анализа целей и задач работы определены условия разработки моделей МО и сформирован план основного этапа моделирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Основной этап моделирования \n",
    "\n",
    "<a id='step22' />\n",
    "\n",
    "[Вернуться к началу](#begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним шаги в соответствии с планом, определенным в предыдущем шаге."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для выполнения шагов сформируем словари с моделями, векторазерами и столбцами для обучения. Затем переберем их в циклах, передавая значения в созданную ранее функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LogisticRegression()': LogisticRegression(max_iter=1000),\n",
    "    'LinearSVC()': LinearSVC(\n",
    "        dual=False, \n",
    "        random_state=RANDOM_STATE, \n",
    "        max_iter=1000, \n",
    "        class_weight='balanced', \n",
    "        C=0.5\n",
    "    ),\n",
    "    'LightGBM': lgb.LGBMClassifier(\n",
    "        random_state=RANDOM_STATE, \n",
    "        class_weight='balanced', \n",
    "        n_estimators=100\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = {\n",
    "    'CountVectorizer': CountVectorizer(stop_words='english',\n",
    "                                       dtype=np.float32),\n",
    "    'TfidfVectorizer': TfidfVectorizer(stop_words=stopwords,\n",
    "                                       dtype=np.float32),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'lemmatized_text',\n",
    "    'lemmatized_text_spacy'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calculate_time = time.time()\n",
    "\n",
    "for column in columns:\n",
    "    for model_name in models:\n",
    "        for vectorizer_name in vectorizers:\n",
    "            score = get_score(models[model_name],\n",
    "                vectorizers[vectorizer_name],\n",
    "                X_train=X_train,\n",
    "                y_train=y_train,\n",
    "                column=column)\n",
    "            stage_time = time.strftime(\"%M минут %S секунд\",\n",
    "                                       time.gmtime(\n",
    "                                           time.time() - calculate_time\n",
    "                                       ))\n",
    "            print(model_name, 'with', vectorizer_name, \n",
    "                  'for column', column, '\\n   --> CV f1_score:', \n",
    "                  round(score, 3),\n",
    "                  '--- Время выполнения:', stage_time)\n",
    "            calculate_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для уточнения наших моделей имеет смысл осуществить подбор некоторых гиперпараметров для сформированных моделей. Для LightGBM целесообразно использовать большее количество деревьев, однако, время обучения будет значительно выше. \n",
    "Попробуем подобрать гиперпараметры логистической регрессии. Указанная модель обучается довольно быстро, гиперпараметров для нее не очень много. Попробуем произвести поиск по сетке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('vectorizer', None),\n",
    "        ('model', None)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'vectorizer': [\n",
    "            CountVectorizer(stop_words='english',\n",
    "                            dtype=np.float32),\n",
    "            TfidfVectorizer(stop_words=stopwords,\n",
    "                            dtype=np.float32),\n",
    "        ],\n",
    "        'model': [LogisticRegression(max_iter=1000)],\n",
    "        'model__penalty': ['l1', 'l2'],\n",
    "        'model__C': range(5, 15),        \n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(\n",
    "    pipe, \n",
    "    param_grid, \n",
    "    n_jobs=-1,\n",
    "    cv=3,\n",
    "    verbose=10,\n",
    "    scoring='f1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gs.fit(X_train['lemmatized_text_spacy'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод по разделу \"Основной этап моделирования\" \n",
    "\n",
    "<a id='conclusion22' />\n",
    "\n",
    "[Вернуться к началу](#begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе работы в соответствии с определенным планом достигнуты следующие результаты:\n",
    "\n",
    "1. Были обучены три модели с двумя векторайзерами для двух лемматизированных столбцом и оценена метрика.\n",
    "2. LinearSVC() единственная показала результаты выше порогового уровня на обучающей выборке. \n",
    "3. Лучшие результаты по итогам кросс-валидации показывает модель LinearSVC() с метрикой f1=0.768. Векторайзер - CountVectorizer, столбец - 'lemmatized_text_spacy'.\n",
    "\n",
    "В результате гиперпараметров для модели логистической регрессии удалось увеличить качество модели (на основании кросс-валидации). Примем лучшей именно модель логистической регрессии с параметрами: C=10 и penalty='l2' для векторайзера TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 3. Оценка качества работы моделей, выбор лучшей модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ разработанных моделей МО \n",
    "\n",
    "<a id='step3' />\n",
    "\n",
    "[Вернуться к началу](#begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В связи с тем, что основным критерием выбора модели является ее метрика f1. То лучшей моделью признается LightGBM. Оценим ее качество на тествой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = get_score(\n",
    "    lgb.LGBMClassifier(\n",
    "        random_state=RANDOM_STATE,\n",
    "        class_weight='balanced',\n",
    "        max_depth=-1,\n",
    "        num_leaves=31,\n",
    "        n_estimators=1000\n",
    "    ),\n",
    "    CountVectorizer(stop_words='english', dtype=np.float32),\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    column='lemmatized_text_spacy',\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = get_score(\n",
    "    LogisticRegression(max_iter=1000,\n",
    "                      C=10, penalty='l2'),\n",
    "    TfidfVectorizer(stop_words=stopwords, dtype=np.float32),\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    column='lemmatized_text_spacy',\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимый результат на тестовой выборке достигнут."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоговый вывод  \n",
    "\n",
    "<a id='conclusion' />\n",
    "\n",
    "[Вернуться к началу](#begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В соответствии с планом работы были достигнуты следующие результаты.\n",
    "\n",
    "**А. Изучение входных данных**\n",
    "\n",
    "Для проведения исследования была получена выборка из 159292 записей. Данные содержат два столбца, один из которых cодержит тексты комментариев, второй - целевой признак (отметку) о токсичности комментариев.\n",
    "\n",
    "**Б. Предобработка данных**\n",
    "\n",
    "В ходе предобработки данных:\n",
    "\n",
    "1. Пропусков и дубликатов в данных не обнаружено.\n",
    "2. Произведена преобработка текстовых данных: токенизация, очистка и лемматизация с использованием WordNet и spaCy. Лучший результат лемматизации показала библиотека spaCy.\n",
    "\n",
    "**В. Результаты исследовательского анализа**\n",
    "\n",
    "В результате проведения исследовательского анализа было выявлено, что имеется существенный дисбаланс классов. Принято решение об учете этой особенности при моделировании (при делении на выборки (stratify) и при обучении модели (аттрибут class_weight='balanced')).\n",
    "\n",
    "**Г. Подготовка данных**\n",
    "\n",
    "Для дальнейшего обучения моделей МО выполнены следующие работы:\n",
    "- разработаны средства автоматизации процесса обучения моделей (pipeline) с учетом результатов предобработки данных;\n",
    "- подготовлены выборки для обучения моделей соотношении 60% тренировочной выборки к 40% тестовой выборки.\n",
    "\n",
    "**Д. Разработка моделей машинного обучения**\n",
    "\n",
    "В результате проведенной работы по обучению моделей достигнуты следующие результаты:\n",
    "1. Были обучены три модели с двумя векторайзерами для двух лемматизированных столбцом и оценена метрика.\n",
    "2. LinearSVC() и LightGBM показали результаты выше порогового уровня на обучающей выборке. \n",
    "3. Лучшие результаты по итогам кросс-валидации показывает модель градиентного бустинга с метрикой f1=0.768 при векторайзере CountVectorizer для текстов, лемматизированных с использованием spaCy.\n",
    "\n",
    "**Е. Анализ разработанных моделей МО**\n",
    "\n",
    "В связи с тем, что критерием выбора модели является ее метрика f1. То лучшей моделью признана LightGBM. \n",
    "\n",
    "**Ж. Оценка качества модели на тестовой выборке**\n",
    "\n",
    "В результате проведенной работы лучшая модель для заказчика - LightGBM, которая показала качество на тестовой выборе: f1=0.780, что выше установленного критерия заказчика.\n",
    "\n",
    "**З. Достижение цели работы**\n",
    "\n",
    "Построена модель МО, которая предсказывает токсичность комментариев с точностью выше определенной требованиями заказчика. Цель работы достигнута.\n",
    "\n",
    "**И. Перспективы развития**\n",
    "\n",
    "Построенная модель показывает среднее качество. Возможно достижение более высоких результатов:\n",
    "1. При подборе гиперпараметров для лучшей модели и отстающих.\n",
    "2. При использовании предобученной модели BERT.\n",
    "\n",
    "Оба варианта развития моделей требуют больших вычислительных мощностей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_time = time.time() - notebook_time_start\n",
    "print(\n",
    "    'Общее время выполнения: ',\n",
    "    time.strftime(\"%H часов %M минут %S секунд\", time.gmtime(notebook_time))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 20513,
    "start_time": "2024-01-30T14:33:39.329Z"
   },
   {
    "duration": 422,
    "start_time": "2024-01-30T14:34:04.480Z"
   },
   {
    "duration": 553,
    "start_time": "2024-01-30T14:34:06.500Z"
   },
   {
    "duration": 98,
    "start_time": "2024-01-30T14:34:07.887Z"
   },
   {
    "duration": 3218,
    "start_time": "2024-01-30T14:34:09.464Z"
   },
   {
    "duration": 2,
    "start_time": "2024-01-30T14:34:13.540Z"
   },
   {
    "duration": 347,
    "start_time": "2024-01-30T14:34:14.791Z"
   },
   {
    "duration": 12878,
    "start_time": "2024-01-30T14:34:29.264Z"
   },
   {
    "duration": 3,
    "start_time": "2024-01-30T14:34:42.145Z"
   },
   {
    "duration": 36,
    "start_time": "2024-01-30T14:34:42.150Z"
   },
   {
    "duration": 7,
    "start_time": "2024-01-30T14:34:42.188Z"
   },
   {
    "duration": 433,
    "start_time": "2024-01-30T14:34:42.197Z"
   },
   {
    "duration": 3,
    "start_time": "2024-01-30T14:34:42.631Z"
   },
   {
    "duration": 42,
    "start_time": "2024-01-30T14:34:42.635Z"
   },
   {
    "duration": 58,
    "start_time": "2024-01-30T14:34:42.679Z"
   },
   {
    "duration": 20,
    "start_time": "2024-01-30T14:34:42.739Z"
   },
   {
    "duration": 25,
    "start_time": "2024-01-30T14:34:42.762Z"
   },
   {
    "duration": 8,
    "start_time": "2024-01-30T14:34:42.789Z"
   },
   {
    "duration": 21,
    "start_time": "2024-01-30T14:34:42.798Z"
   },
   {
    "duration": 9,
    "start_time": "2024-01-30T14:34:42.821Z"
   },
   {
    "duration": 5,
    "start_time": "2024-01-30T14:34:42.831Z"
   },
   {
    "duration": 2177,
    "start_time": "2024-01-30T14:34:42.838Z"
   },
   {
    "duration": 36,
    "start_time": "2024-01-30T14:34:45.017Z"
   },
   {
    "duration": 66,
    "start_time": "2024-01-30T14:34:45.055Z"
   },
   {
    "duration": 87,
    "start_time": "2024-01-30T14:34:45.122Z"
   },
   {
    "duration": 273,
    "start_time": "2024-01-30T14:34:45.211Z"
   },
   {
    "duration": 3,
    "start_time": "2024-01-30T14:34:45.485Z"
   },
   {
    "duration": 7420,
    "start_time": "2024-01-30T14:34:45.493Z"
   },
   {
    "duration": 2,
    "start_time": "2024-01-30T14:34:52.914Z"
   },
   {
    "duration": 22,
    "start_time": "2024-01-30T14:34:52.918Z"
   },
   {
    "duration": 83356,
    "start_time": "2024-01-30T14:34:52.941Z"
   },
   {
    "duration": 4,
    "start_time": "2024-01-30T14:36:16.299Z"
   },
   {
    "duration": 1895,
    "start_time": "2024-01-30T14:36:16.304Z"
   },
   {
    "duration": 9,
    "start_time": "2024-01-30T14:36:18.201Z"
   },
   {
    "duration": 73,
    "start_time": "2024-01-30T14:36:18.213Z"
   },
   {
    "duration": 34,
    "start_time": "2024-01-30T14:36:18.287Z"
   },
   {
    "duration": 78,
    "start_time": "2024-01-30T14:36:18.323Z"
   },
   {
    "duration": 14,
    "start_time": "2024-01-30T14:36:18.402Z"
   },
   {
    "duration": 829,
    "start_time": "2024-01-30T14:36:18.418Z"
   },
   {
    "duration": 0,
    "start_time": "2024-01-30T14:36:19.249Z"
   },
   {
    "duration": 0,
    "start_time": "2024-01-30T14:36:19.251Z"
   },
   {
    "duration": 0,
    "start_time": "2024-01-30T14:36:19.253Z"
   },
   {
    "duration": 0,
    "start_time": "2024-01-30T14:36:19.254Z"
   },
   {
    "duration": 0,
    "start_time": "2024-01-30T14:36:19.255Z"
   },
   {
    "duration": 0,
    "start_time": "2024-01-30T14:36:19.257Z"
   },
   {
    "duration": 0,
    "start_time": "2024-01-30T14:36:19.259Z"
   },
   {
    "duration": 0,
    "start_time": "2024-01-30T14:36:19.260Z"
   },
   {
    "duration": 0,
    "start_time": "2024-01-30T14:36:19.262Z"
   },
   {
    "duration": 0,
    "start_time": "2024-01-30T14:36:19.263Z"
   },
   {
    "duration": 0,
    "start_time": "2024-01-30T14:36:19.264Z"
   },
   {
    "duration": 0,
    "start_time": "2024-01-30T14:36:19.295Z"
   },
   {
    "duration": 2,
    "start_time": "2024-01-30T14:39:35.374Z"
   },
   {
    "duration": 80,
    "start_time": "2024-01-30T14:39:41.234Z"
   },
   {
    "duration": 113,
    "start_time": "2024-01-30T14:39:44.941Z"
   },
   {
    "duration": 3,
    "start_time": "2024-01-30T14:39:46.029Z"
   },
   {
    "duration": 90,
    "start_time": "2024-01-30T14:39:46.211Z"
   },
   {
    "duration": 4,
    "start_time": "2024-01-30T14:39:46.532Z"
   },
   {
    "duration": 4,
    "start_time": "2024-01-30T14:39:47.021Z"
   },
   {
    "duration": 4,
    "start_time": "2024-01-30T14:39:51.140Z"
   },
   {
    "duration": 3,
    "start_time": "2024-01-30T14:39:51.513Z"
   },
   {
    "duration": 2,
    "start_time": "2024-01-30T14:39:51.725Z"
   },
   {
    "duration": 3,
    "start_time": "2024-01-30T14:39:51.911Z"
   },
   {
    "duration": 31820,
    "start_time": "2024-01-30T14:39:52.467Z"
   },
   {
    "duration": 13136,
    "start_time": "2024-01-30T14:41:11.513Z"
   },
   {
    "duration": 615,
    "start_time": "2024-01-30T14:41:24.651Z"
   },
   {
    "duration": 593,
    "start_time": "2024-01-30T14:41:25.268Z"
   },
   {
    "duration": 22,
    "start_time": "2024-01-30T14:41:25.862Z"
   },
   {
    "duration": 3106,
    "start_time": "2024-01-30T14:41:25.886Z"
   },
   {
    "duration": 3,
    "start_time": "2024-01-30T14:41:28.993Z"
   },
   {
    "duration": 364,
    "start_time": "2024-01-30T14:41:28.998Z"
   },
   {
    "duration": 5,
    "start_time": "2024-01-30T14:41:29.364Z"
   },
   {
    "duration": 28,
    "start_time": "2024-01-30T14:41:29.370Z"
   },
   {
    "duration": 33,
    "start_time": "2024-01-30T14:41:29.399Z"
   },
   {
    "duration": 24,
    "start_time": "2024-01-30T14:41:29.434Z"
   },
   {
    "duration": 42,
    "start_time": "2024-01-30T14:41:29.460Z"
   },
   {
    "duration": 34,
    "start_time": "2024-01-30T14:41:29.503Z"
   },
   {
    "duration": 35,
    "start_time": "2024-01-30T14:41:29.540Z"
   },
   {
    "duration": 1735,
    "start_time": "2024-01-30T14:41:29.577Z"
   },
   {
    "duration": 33,
    "start_time": "2024-01-30T14:41:31.314Z"
   },
   {
    "duration": 70,
    "start_time": "2024-01-30T14:41:31.348Z"
   },
   {
    "duration": 61,
    "start_time": "2024-01-30T14:41:31.420Z"
   },
   {
    "duration": 240,
    "start_time": "2024-01-30T14:41:31.483Z"
   },
   {
    "duration": 4,
    "start_time": "2024-01-30T14:41:31.725Z"
   },
   {
    "duration": 7638,
    "start_time": "2024-01-30T14:41:31.730Z"
   },
   {
    "duration": 2,
    "start_time": "2024-01-30T14:41:39.370Z"
   },
   {
    "duration": 21,
    "start_time": "2024-01-30T14:41:39.373Z"
   },
   {
    "duration": 84644,
    "start_time": "2024-01-30T14:41:39.396Z"
   },
   {
    "duration": 4,
    "start_time": "2024-01-30T14:43:04.041Z"
   },
   {
    "duration": 1625,
    "start_time": "2024-01-30T14:43:04.047Z"
   },
   {
    "duration": 10,
    "start_time": "2024-01-30T14:43:05.673Z"
   },
   {
    "duration": 69,
    "start_time": "2024-01-30T14:43:05.684Z"
   },
   {
    "duration": 27,
    "start_time": "2024-01-30T14:43:05.755Z"
   },
   {
    "duration": 124,
    "start_time": "2024-01-30T14:43:05.784Z"
   },
   {
    "duration": 13,
    "start_time": "2024-01-30T14:43:05.910Z"
   },
   {
    "duration": 111,
    "start_time": "2024-01-30T14:43:05.925Z"
   },
   {
    "duration": 19,
    "start_time": "2024-01-30T14:43:06.038Z"
   },
   {
    "duration": 3,
    "start_time": "2024-01-30T14:43:06.058Z"
   },
   {
    "duration": 103,
    "start_time": "2024-01-30T14:43:06.062Z"
   },
   {
    "duration": 4,
    "start_time": "2024-01-30T14:43:06.166Z"
   },
   {
    "duration": 20,
    "start_time": "2024-01-30T14:43:06.171Z"
   },
   {
    "duration": 14,
    "start_time": "2024-01-30T14:43:06.192Z"
   },
   {
    "duration": 40,
    "start_time": "2024-01-30T14:43:06.207Z"
   },
   {
    "duration": 9,
    "start_time": "2024-01-30T14:43:06.249Z"
   },
   {
    "duration": 14,
    "start_time": "2024-01-30T14:43:06.261Z"
   },
   {
    "duration": 251653,
    "start_time": "2024-01-30T15:13:28.411Z"
   },
   {
    "duration": 31,
    "start_time": "2024-01-30T15:17:40.065Z"
   },
   {
    "duration": 852,
    "start_time": "2024-02-03T13:56:38.099Z"
   },
   {
    "duration": 786,
    "start_time": "2024-02-03T13:56:39.626Z"
   },
   {
    "duration": 628,
    "start_time": "2024-02-03T13:57:15.119Z"
   },
   {
    "duration": 758,
    "start_time": "2024-02-03T13:57:15.748Z"
   },
   {
    "duration": 30,
    "start_time": "2024-02-03T13:57:16.508Z"
   },
   {
    "duration": 4104,
    "start_time": "2024-02-03T13:57:16.541Z"
   },
   {
    "duration": 5,
    "start_time": "2024-02-03T13:57:20.646Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "230px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
