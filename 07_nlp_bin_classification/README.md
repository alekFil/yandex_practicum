# Разработка модели для классифицикации комментариев на позитивные и негативные

## Цель работы

Построить модель, которая определит тональность комментариев в новом сервисе закачика.

## Планируемое использование результата работы

Заказчику необходим инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

## Входные данные

Заказчик предоставил набор данных с разметкой о токсичности. Негативный комментарий - класс 1, нейтральный комментарий - класс 0.

## Задачи работы

1. Подготовить данные для формирования модели.
2. Разработать несколько моделей машинного обучения (МО) для предсказания.
3. Оценить качество работы моделей. Выбрать лучшую модель.
4. Протестировать лучшую модель.

## Критерий качества от заказчика

Значение метрики F1 на тестовой выборке должно быть не мешьше 0.75.

## Теги
`Python`, `Pandas`, `Scikit-learn`, `Pipeline`, `NLTK`, `TF-IDF`, `BERT`, `SpaCy`

## Результаты и выводы

Для проведения исследования была получена выборка из 159292 записей. Проведена предобработки данных, их исследовательский анализ и подготовка к обучению. 

В результате проведенной работы по обучению моделей достигнуты следующие результаты:
1. Были обучены три модели с двумя векторайзерами для двух лемматизированных столбцом и оценена метрика.
2. LinearSVC() и LightGBM показали результаты выше порогового уровня на обучающей выборке. 
3. Лучшие результаты по итогам кросс-валидации показывает модель градиентного бустинга с метрикой f1=0.768 при векторайзере CountVectorizer для текстов, лемматизированных с использованием spaCy.

Лучшей моделью признана LightGBM. 

В результате проведенной работы лучшая модель для заказчика - LightGBM, которая показала качество на тестовой выборе: f1=0.780, что выше установленного критерия заказчика.

## Достижение цели работы

Построена модель МО, которая предсказывает токсичность комментариев с точностью выше определенной требованиями заказчика. Цель работы достигнута.

## Перспективы развития

Построенная модель показывает среднее качество. Возможно достижение более высоких результатов при использовании предобученной модели BERT, что требует больших вычислительных мощностей.